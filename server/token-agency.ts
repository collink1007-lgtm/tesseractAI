import fs from "fs";
import path from "path";

interface LLMCallRecord {
  provider: string;
  tokensUsed: number;
  cacheHit: boolean;
  responseQuality: number;
  timestamp: number;
  promptLength: number;
  responseLength: number;
}

interface EfficiencyMetrics {
  tokensPerUsefulResponse: number;
  cacheHitRate: number;
  costPerInteraction: number;
  avgResponseQuality: number;
  totalTokensUsed: number;
  totalCalls: number;
  totalCacheHits: number;
  providerDistribution: Record<string, number>;
  hourlyUsage: Record<string, number>;
  wasteTokens: number;
}

interface TokenAgencyState {
  running: boolean;
  startedAt: number;
  totalCallsTracked: number;
  totalTokensTracked: number;
  totalCacheHits: number;
  reportsGenerated: number;
  lastReportTime: number;
  callHistory: LLMCallRecord[];
  efficiencyReports: EfficiencyReport[];
  promptCompressionSavings: number;
  timingVariance: number[];
}

interface EfficiencyReport {
  timestamp: number;
  period: string;
  metrics: EfficiencyMetrics;
  recommendations: string[];
  grade: string;
}

const MAX_CALL_HISTORY = 1000;
const MAX_REPORTS = 50;
const REPORT_INTERVAL = 60 * 60 * 1000;
const PERSISTENCE_FILE = path.join(process.cwd(), "server", "token-agency.json");

const state: TokenAgencyState = {
  running: false,
  startedAt: 0,
  totalCallsTracked: 0,
  totalTokensTracked: 0,
  totalCacheHits: 0,
  reportsGenerated: 0,
  lastReportTime: 0,
  callHistory: [],
  efficiencyReports: [],
  promptCompressionSavings: 0,
  timingVariance: [],
};

let reportInterval: ReturnType<typeof setInterval> | null = null;

function loadState() {
  try {
    if (fs.existsSync(PERSISTENCE_FILE)) {
      const data = JSON.parse(fs.readFileSync(PERSISTENCE_FILE, "utf-8"));
      state.totalCallsTracked = data.totalCallsTracked || 0;
      state.totalTokensTracked = data.totalTokensTracked || 0;
      state.totalCacheHits = data.totalCacheHits || 0;
      state.reportsGenerated = data.reportsGenerated || 0;
      state.lastReportTime = data.lastReportTime || 0;
      state.promptCompressionSavings = data.promptCompressionSavings || 0;
      state.efficiencyReports = (data.efficiencyReports || []).slice(-MAX_REPORTS);
    }
  } catch {}
}

function saveState() {
  try {
    const toSave = {
      totalCallsTracked: state.totalCallsTracked,
      totalTokensTracked: state.totalTokensTracked,
      totalCacheHits: state.totalCacheHits,
      reportsGenerated: state.reportsGenerated,
      lastReportTime: state.lastReportTime,
      promptCompressionSavings: state.promptCompressionSavings,
      efficiencyReports: state.efficiencyReports.slice(-MAX_REPORTS),
    };
    fs.writeFileSync(PERSISTENCE_FILE, JSON.stringify(toSave, null, 2));
  } catch {}
}

export function startTokenAgency() {
  if (state.running) return;
  loadState();
  state.running = true;
  state.startedAt = Date.now();

  reportInterval = setInterval(() => {
    generateEfficiencyReport();
  }, REPORT_INTERVAL);

  console.log("[TokenAgency] Token & Rate Limit Optimization Agency started");
}

export function trackLLMCall(data: {
  provider: string;
  tokensUsed: number;
  cacheHit: boolean;
  promptLength: number;
  responseLength: number;
}) {
  const quality = data.responseLength > 100 ? Math.min(100, Math.round((data.responseLength / Math.max(data.promptLength, 1)) * 50)) : data.responseLength > 30 ? 50 : 10;

  const record: LLMCallRecord = {
    provider: data.provider,
    tokensUsed: data.tokensUsed,
    cacheHit: data.cacheHit,
    responseQuality: quality,
    timestamp: Date.now(),
    promptLength: data.promptLength,
    responseLength: data.responseLength,
  };

  state.callHistory.push(record);
  if (state.callHistory.length > MAX_CALL_HISTORY) {
    state.callHistory = state.callHistory.slice(-MAX_CALL_HISTORY);
  }

  state.totalCallsTracked++;
  state.totalTokensTracked += data.tokensUsed;
  if (data.cacheHit) state.totalCacheHits++;

  const jitter = Math.floor(Math.random() * 500) + 100;
  state.timingVariance.push(jitter);
  if (state.timingVariance.length > 100) {
    state.timingVariance = state.timingVariance.slice(-100);
  }

  if (state.totalCallsTracked % 50 === 0) {
    saveState();
  }
}

export function optimizePrompt(text: string): string {
  const original = text.length;
  let optimized = text
    .replace(/\n{3,}/g, "\n\n")
    .replace(/\s{3,}/g, " ")
    .replace(/\t+/g, " ")
    .replace(/---+/g, "---")
    .replace(/===+/g, "===")
    .replace(/\*\*\*+/g, "***")
    .trim();

  const saved = original - optimized.length;
  if (saved > 0) {
    state.promptCompressionSavings += saved;
  }

  return optimized;
}

function calculateMetrics(records: LLMCallRecord[]): EfficiencyMetrics {
  if (records.length === 0) {
    return {
      tokensPerUsefulResponse: 0,
      cacheHitRate: 0,
      costPerInteraction: 0,
      avgResponseQuality: 0,
      totalTokensUsed: 0,
      totalCalls: 0,
      totalCacheHits: 0,
      providerDistribution: {},
      hourlyUsage: {},
      wasteTokens: 0,
    };
  }

  const totalTokens = records.reduce((s, r) => s + r.tokensUsed, 0);
  const cacheHits = records.filter(r => r.cacheHit).length;
  const usefulResponses = records.filter(r => r.responseQuality > 30).length;
  const avgQuality = Math.round(records.reduce((s, r) => s + r.responseQuality, 0) / records.length);
  const wasteTokens = records.filter(r => r.responseQuality < 20).reduce((s, r) => s + r.tokensUsed, 0);

  const providerDist: Record<string, number> = {};
  const hourlyUsage: Record<string, number> = {};
  for (const r of records) {
    const pName = r.provider.replace(" (cached)", "");
    providerDist[pName] = (providerDist[pName] || 0) + 1;
    const hour = new Date(r.timestamp).getHours().toString().padStart(2, "0") + ":00";
    hourlyUsage[hour] = (hourlyUsage[hour] || 0) + r.tokensUsed;
  }

  const costEstimate = totalTokens * 0.000002;

  return {
    tokensPerUsefulResponse: usefulResponses > 0 ? Math.round(totalTokens / usefulResponses) : 0,
    cacheHitRate: Math.round((cacheHits / records.length) * 100),
    costPerInteraction: Math.round(costEstimate * 10000) / 10000,
    avgResponseQuality: avgQuality,
    totalTokensUsed: totalTokens,
    totalCalls: records.length,
    totalCacheHits: cacheHits,
    providerDistribution: providerDist,
    hourlyUsage,
    wasteTokens,
  };
}

function gradeEfficiency(metrics: EfficiencyMetrics): string {
  let score = 0;
  if (metrics.cacheHitRate > 40) score += 3;
  else if (metrics.cacheHitRate > 20) score += 2;
  else if (metrics.cacheHitRate > 5) score += 1;

  if (metrics.avgResponseQuality > 70) score += 3;
  else if (metrics.avgResponseQuality > 50) score += 2;
  else if (metrics.avgResponseQuality > 30) score += 1;

  if (metrics.wasteTokens < metrics.totalTokensUsed * 0.1) score += 2;
  else if (metrics.wasteTokens < metrics.totalTokensUsed * 0.25) score += 1;

  const providerCount = Object.keys(metrics.providerDistribution).length;
  if (providerCount >= 3) score += 2;
  else if (providerCount >= 2) score += 1;

  if (score >= 9) return "A+";
  if (score >= 7) return "A";
  if (score >= 5) return "B";
  if (score >= 3) return "C";
  return "D";
}

function generateRecommendations(metrics: EfficiencyMetrics): string[] {
  const recs: string[] = [];

  if (metrics.cacheHitRate < 15) {
    recs.push("Cache hit rate is low. Consider increasing cache TTL or expanding cache size for repeated queries.");
  }
  if (metrics.avgResponseQuality < 50) {
    recs.push("Average response quality below target. Review prompt templates and consider using higher-capability models for complex queries.");
  }
  if (metrics.wasteTokens > metrics.totalTokensUsed * 0.2) {
    recs.push("High token waste detected. Implement stricter minimum response length filtering and prompt validation.");
  }

  const providers = Object.entries(metrics.providerDistribution);
  if (providers.length === 1) {
    recs.push("All calls routed to single provider. Distribute across multiple providers for resilience and cost optimization.");
  }
  const maxProvider = providers.sort((a, b) => b[1] - a[1])[0];
  if (maxProvider && maxProvider[1] > metrics.totalCalls * 0.8) {
    recs.push(`Provider ${maxProvider[0]} handling ${Math.round((maxProvider[1] / metrics.totalCalls) * 100)}% of calls. Consider load balancing.`);
  }

  if (recs.length === 0) {
    recs.push("All efficiency metrics within optimal range. Continue current optimization strategy.");
  }

  return recs;
}

function generateEfficiencyReport(): EfficiencyReport {
  const oneHourAgo = Date.now() - REPORT_INTERVAL;
  const recentRecords = state.callHistory.filter(r => r.timestamp > oneHourAgo);
  const metrics = calculateMetrics(recentRecords);
  const recommendations = generateRecommendations(metrics);
  const grade = gradeEfficiency(metrics);

  const report: EfficiencyReport = {
    timestamp: Date.now(),
    period: "1 hour",
    metrics,
    recommendations,
    grade,
  };

  state.efficiencyReports.push(report);
  if (state.efficiencyReports.length > MAX_REPORTS) {
    state.efficiencyReports = state.efficiencyReports.slice(-MAX_REPORTS);
  }

  state.reportsGenerated++;
  state.lastReportTime = Date.now();
  saveState();

  console.log(`[TokenAgency] Efficiency report #${state.reportsGenerated}: Grade ${grade}, ${metrics.totalCalls} calls, ${metrics.cacheHitRate}% cache hit rate`);

  return report;
}

export function getTokenStats(): {
  running: boolean;
  startedAt: number;
  totalCallsTracked: number;
  totalTokensTracked: number;
  totalCacheHits: number;
  cacheHitRate: number;
  reportsGenerated: number;
  lastReportTime: number;
  promptCompressionSavings: number;
  recentCallCount: number;
  providerDistribution: Record<string, number>;
  avgTimingVariance: number;
} {
  const fiveMinAgo = Date.now() - 5 * 60 * 1000;
  const recentCalls = state.callHistory.filter(r => r.timestamp > fiveMinAgo);

  const providerDist: Record<string, number> = {};
  for (const r of state.callHistory.slice(-200)) {
    const p = r.provider.replace(" (cached)", "");
    providerDist[p] = (providerDist[p] || 0) + 1;
  }

  const avgVariance = state.timingVariance.length > 0
    ? Math.round(state.timingVariance.reduce((a, b) => a + b, 0) / state.timingVariance.length)
    : 0;

  return {
    running: state.running,
    startedAt: state.startedAt,
    totalCallsTracked: state.totalCallsTracked,
    totalTokensTracked: state.totalTokensTracked,
    totalCacheHits: state.totalCacheHits,
    cacheHitRate: state.totalCallsTracked > 0 ? Math.round((state.totalCacheHits / state.totalCallsTracked) * 100) : 0,
    reportsGenerated: state.reportsGenerated,
    lastReportTime: state.lastReportTime,
    promptCompressionSavings: state.promptCompressionSavings,
    recentCallCount: recentCalls.length,
    providerDistribution: providerDist,
    avgTimingVariance: avgVariance,
  };
}

export function getEfficiencyReport(): EfficiencyReport | null {
  if (state.efficiencyReports.length === 0) {
    return generateEfficiencyReport();
  }
  const latest = state.efficiencyReports[state.efficiencyReports.length - 1];
  if (Date.now() - latest.timestamp > REPORT_INTERVAL) {
    return generateEfficiencyReport();
  }
  return latest;
}

export function getTokenAgencyBriefing(): string {
  const stats = getTokenStats();
  const report = state.efficiencyReports.length > 0 ? state.efficiencyReports[state.efficiencyReports.length - 1] : null;

  const topProviders = Object.entries(stats.providerDistribution)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 5)
    .map(([name, count]) => `${name}: ${count} calls`)
    .join(", ");

  return `Token & Rate Limit Agency Report:
- Status: ${stats.running ? "ACTIVE" : "OFFLINE"}
- Total Calls Tracked: ${stats.totalCallsTracked}
- Total Tokens Used: ${stats.totalTokensTracked}
- Cache Hit Rate: ${stats.cacheHitRate}%
- Prompt Compression Savings: ${stats.promptCompressionSavings} chars
- Reports Generated: ${stats.reportsGenerated}
- Recent Calls (5min): ${stats.recentCallCount}
- Provider Distribution: ${topProviders || "No data"}
- Efficiency Grade: ${report?.grade || "N/A"}
- Avg Request Timing Variance: ${stats.avgTimingVariance}ms
${report ? `- Recommendations: ${report.recommendations[0] || "None"}` : ""}`;
}
